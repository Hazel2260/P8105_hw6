---
title: "p8105_hw6"
author: "Qingzhen Sun"
date: "2022-12-01"
output: html_document
---

```{r}
library(tidyverse)
library(modelr)


```

## Problem 2 

#### Load the raw data, and discrible the raw data.
```{r}
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homi_data = read_csv(url(urlfile))%>%
  janitor::clean_names()
dim(homi_data)
```
#### Tidy the raw data and adding new variables.

```{r}
tidy_homi = homi_data%>%
  mutate(city_state = str_c(city, ",", state))%>%
  mutate(situation = (disposition == "Closed by arrest"))%>%
  mutate(victim_age = as.numeric(victim_age))%>%
  filter(victim_race == "White"| victim_race== "Black")%>%
  filter(!city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL"))
  
  
```

#### Fit in the model and do analysis for city Baltimore

```{r}
homi_BD = tidy_homi%>%
  filter(city_state == "Baltimore,MD")%>%
  select(situation, victim_race, victim_age, victim_sex)%>%
  glm(situation ~ victim_race + victim_sex + victim_age, data = ., family = "binomial" )%>%
  broom::tidy() %>%
  mutate(OR = exp(estimate),
         OR_lower = OR - qnorm(0.95)*std.error,
         OR_upper = OR + qnorm(0.95)*std.error)%>%
  select(OR, OR_lower, OR_upper, estimate)%>%
  save(file = "result/homi_BD.RData")
  
```
#### fit model for each city.
```{r}
city_nest = 
  tidy_homi %>%
  select(city_state,situation, victim_race, victim_age, victim_sex) %>%
  nest(data = -city_state)%>%
  mutate(
    model  = map(.x = data,  ~glm(situation ~ victim_race + victim_sex + victim_age, data = .x, family = "binomial" )),
    result = map(model, broom::tidy))%>%
  unnest(result)%>%
  filter(term == "victim_sexMale")%>%
  mutate(OR = exp(estimate),
         OR_lower = OR - qnorm(0.95)*std.error,
         OR_upper = OR + qnorm(0.95)*std.error)%>%
  select(city_state, OR, OR_lower, OR_upper)
  
city_nest

```

#### plot the graph for each city.
```{r}
plot_city = city_nest%>%
  ggplot(aes(x = city_state, y = OR))+
  geom_point()+
  geom_errorbar(aes(ymin = OR_lower, ymax = OR_upper))
plot_city
```
## problem3

####  load data and clean. 
```{r}
bwt_data = read_csv("data/birthweight.csv")%>%
  janitor::clean_names()%>%
  mutate(
    babysex = factor(babysex),
    frace = factor(frace),
    malform = factor(malform),
    mrace = factor(mrace)
  ) 
```
#### regression model for bwt using backward model.
```{r}
module_0 = lm(bwt ~., data = bwt_data) 
step(module_0, direction = "backward") %>% broom::tidy()
```

```{r}
module_1 = lm(bwt ~ babysex + bhead + blength + fincome + delwt + gaweeks + mheight + mrace + parity + ppwt + smoken, data = bwt_data)
```

#### model residuals against fitted values â€“ use add_predictions and add_residuals

```{r}
bwt_data %>% 
  add_predictions(module_1) %>% 
  add_residuals(module_1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = "Residuals vs. Fitted Values"
  )
```

#### Other modle for bwt prediciton.
```{r}
module_2 = lm(bwt ~ blength + gaweeks, data = bwt_data) 
module_3 = lm(bwt ~ bhead + blength + babysex + bhead * blength * gaweeks, data = bwt_data)
```

#### three modules comparison.

```{r}
cv_data =
  crossv_mc(bwt_data, 100) %>% 
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble)
  ) %>% 
  mutate(
    module_1 = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + fincome + delwt + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)), 
    module_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    module_3 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength * gaweeks, data = .x))
  ) %>% 
  mutate(
    rmse_fit1 = map2_dbl(.x = module_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_fit2 = map2_dbl(.x = module_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_fit3 = map2_dbl(.x = module_3, .y = test, ~rmse(model = .x, data = .y))
  )
```


```{r}
cv_data %>% 
  summarize(
     rmse_fit1_avg = mean(rmse_fit1),
     rmse_fit2_avg = mean(rmse_fit2),
     rmse_fit3_avg = mean(rmse_fit3)
  )
```
From the result above, the best modle is module_1 which used the backward selection since it has the lowest rmse value. The 2nd choice is module_3 which used the three way interaction. And the modle_2 is the worse one since it has the highest rmse value.


